{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/fmottes/jax-morph/blob/eqx\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" style=\"width:250px;\"/>\n",
    "  </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization of stochastic simulations\n",
    "\n",
    "We now turn to the problem of optimizing a simulation that involves steps where some sort of sampling is involved. The sampling step is not differentiable in the classic sense, so it is not possible to propagate gradients through the simulation directly.\n",
    "\n",
    "In this notebook we will use some toy problems to illustrate the basic variants of the two main ideas used in general to overcome the non-differentiability of the sampling step:\n",
    "\n",
    "1. **Score function**: The idea is to use the score function to estimate the gradient of the expectation of the function of interest. This idea is at the core of the REINFORCE algorithm, the one we adopt also for the optimizations carried out in the paper.\n",
    "\n",
    "2. **Reparametrization**: The idea is to reparametrize the sampling step in a way that makes it differentiable, by \"decoupling\" the learnable parameters from the randomness. This usually involves a transformation of the random variable that depends on the learnable parameters, and that is differentiable with respect to them. Heuristically, though, it is fairly hard to make this second approach work in practice, especially in complex models like ours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as np\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "jax.config.update(\"jax_debug_nans\", True)\n",
    "\n",
    "key = jax.random.PRNGKey(0) # random number generator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "from tqdm import trange"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
